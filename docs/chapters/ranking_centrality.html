<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
  <meta charset="utf-8">
  <meta name="generator" content="quarto-0.9.165">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Math 168: Introduction to Networks - 6&nbsp; Network Exploration</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>

  <script src="../site_libs/quarto-nav/quarto-nav.js"></script>
  <script src="../site_libs/quarto-nav/headroom.min.js"></script>
  <script src="../site_libs/clipboard/clipboard.min.js"></script>
  <meta name="quarto:offset" content="../">
  <script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
  <script src="../site_libs/quarto-search/fuse.min.js"></script>
  <script src="../site_libs/quarto-search/quarto-search.js"></script>
  <link href="../chapters/agent_based_modeling.html" rel="next">
  <link href="../chapters/clustering_community.html" rel="prev">
  <script src="../site_libs/quarto-html/quarto.js"></script>
  <script src="../site_libs/quarto-html/popper.min.js"></script>
  <script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
  <script src="../site_libs/quarto-html/anchor.min.js"></script>
  <link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
  <link id="quarto-text-highlighting-styles" href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
  <script src="../site_libs/bootstrap/bootstrap.min.js"></script>
  <link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
  <link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
  <script id="quarto-search-options" type="application/json">{
    "location": "sidebar",
    "copy-button": false,
    "collapse-after": 3,
    "panel-placement": "start",
    "type": "textbox",
    "limit": 20,
    "language": {
      "search-no-results-text": "No results",
      "search-matching-documents-text": "matching documents",
      "search-copy-link-title": "Copy link to search",
      "search-hide-matches-text": "Hide additional matches",
      "search-more-match-text": "more match in this document",
      "search-more-matches-text": "more matches in this document",
      "search-clear-button-title": "Clear",
      "search-detached-cancel-button-title": "Cancel",
      "search-submit-button-title": "Submit"
    }
  }</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body class="floating slimcontent">
<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Network Exploration</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Math 168: <br><b>Introduction to Networks</b></a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Welcome!</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="../syllabus/syllabus.html" class="sidebar-item-text sidebar-link">Syllabus</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../syllabus/specifications.html" class="sidebar-item-text sidebar-link">Standard Specifications</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../syllabus/resources.html" class="sidebar-item-text sidebar-link">Health, Wellbeing, and Equity</a>
  </div>
</li>
    </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="../chapters/intro.html" class="sidebar-item-text sidebar-link">Lecture Notes</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/measurement.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Measuring Networks</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/random_graphs.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Random Graphs: Erdős–Rényi</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/degree_sequences.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Random Graphs: Degree Sequences</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/interlude_research_survey.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Interlude: A Rapid Survey of Research Questions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/clustering_community.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Clustering and Community Detection</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/ranking_centrality.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Network Exploration</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/agent_based_modeling.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Agent-Based Modeling on Networks</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/social_responsibility.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Networks and Social Responsibility</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/dynamics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Dynamics on Networks</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Appendices</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/additional_resources.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Network Science Resources</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/acknowledgements.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/references.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">References</span></a>
  </div>
</li>
    </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#sec-srw" class="nav-link active" data-scroll-target="#sec-srw"> <span class="header-section-number">6.1</span> The Simple Random Walk</a>
<ul class="collapse">
<li><a href="#stationary-distribution-existence-and-uniqueness" class="nav-link" data-scroll-target="#stationary-distribution-existence-and-uniqueness">Stationary Distribution: Existence and Uniqueness</a></li>
<li><a href="#stationary-distribution-structure" class="nav-link" data-scroll-target="#stationary-distribution-structure">Stationary Distribution: Structure</a></li>
</ul></li>
<li><a href="#exploration-and-ranking-pagerank" class="nav-link" data-scroll-target="#exploration-and-ranking-pagerank"> <span class="header-section-number">6.2</span> Exploration and Ranking: PageRank</a>
<ul class="collapse">
<li><a href="#implementation" class="nav-link" data-scroll-target="#implementation">Implementation</a></li>
</ul></li>
<li><a href="#seeded-pagerank" class="nav-link" data-scroll-target="#seeded-pagerank"> <span class="header-section-number">6.3</span> Seeded PageRank</a></li>
</ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">
<header id="title-block-header" class="quarto-title-block default">

<div class="quarto-title"><h1 class="title d-none d-lg-block display-7"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Network Exploration</span></h1></div></header>

<p>Suppose that we have a very large network, and we’d like to explore it. Perhaps we don’t even have access to all the edges. This is a common situation in data collection. A webscraper for gathering data, for example, doesn’t have access to the entire network of webpages to be scraped; usually it has access to <em>one page at a time</em> and the links it contains. At each stage, the webscraper needs to follow a link in order to get the next piece of information.</p>
<p>There are many ways to explore a network, but the most fundamental one is the <em>simple random walk</em>. We’ll discuss the simple random walk, highlight some of its core properties, and connect it to some ideas that we’ve already seen. Then, we’ll introduce the <em>teleporting random walk</em>, which is the foundation of the internet-changing PageRank algorithm originally used by Google. Finally, we’ll take another look network navigation and the small-world phenomenon.</p>
<section id="sec-srw" class="level2 page-columns page-full" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="sec-srw"><span class="header-section-number">6.1</span> The Simple Random Walk</h2>
<p>The simple random walk is easier to describe in English than it is to formulate mathematically. In intuitive terms, we imagine a walker who starts at some node <span class="math inline">\(i\)</span> in the graph. The walker then picks one of the neighbors <span class="math inline">\(j\)</span> of <span class="math inline">\(i\)</span> uniformly at random, and moves to <span class="math inline">\(j\)</span>. Then, the walker picks one of the neighbors <span class="math inline">\(k\)</span> of <span class="math inline">\(j\)</span> uniformly at random, and moves to <span class="math inline">\(k\)</span>, and so on.</p>
<div class="callout-note callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-simple-random-walk" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6.1 (Simple Random Walk (SRW)) </strong></span></p>
<p>A <strong>simple random walk</strong> on a graph <span class="math inline">\(G\)</span> with adjacency matrix <span class="math inline">\(\mathbf{A}\in \mathbb{R}^{n\times n}\)</span> is a countable sequence of random variables <span class="math inline">\(X_1,\ldots,X_t,\ldots\)</span> which take values in the node set <span class="math inline">\(N\)</span> of <span class="math inline">\(G\)</span>. We have <span class="math display">\[
\begin{aligned}
\mathbb{P}(X_{t+1} = i | X_t = j_t, X_{t-1} = j_{t-1},\ldots,X_{1} = j_1) &amp;=  \mathbb{P}(X_{t+1} = i | X_t = j_t) \\
&amp;= \begin{cases}
        \frac{1}{d_j} &amp;\quad j \text{ is connected to } i \\
        0 &amp;\quad \text{otherwise.}
    \end{cases} \\
    &amp;= \frac{a_{ij}}{k_j}\;.
\end{aligned}
\]</span></p>
</div>
</div>
</div>
</div>
<p>In <a href="#def-simple-random-walk">Definition&nbsp;<span>6.1</span></a>, the first equality is the <em><a href="https://en.wikipedia.org/wiki/Markov_property">Markov property</a></em>: the future state of the random walk depends only on where it is right now (i.e.&nbsp;the value of <span class="math inline">\(X_t\)</span>), not where it’s been previously. The second and third equalities give mathematical structure to the idea of “picking a node connected to <span class="math inline">\(j\)</span> uniformly at random.”</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="aside">Note: relative to Problem 3 in HW0, I have switched the indices in this matrix in order to better align with Newman’s discussion in 6.14.3.</span></div></div>
<div class="callout-note callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-transition-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6.2 (Transition Matrix of a SRW) </strong></span></p>
<p>The <strong>transition matrix</strong> of a simple random walk on a graph <span class="math inline">\(G\)</span> with adjacency matrix <span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(\mathbf{P} = \mathbf{A}\mathbf{K}^{-1}\)</span>. Its entries are <span class="math inline">\(p_{ij} = a_{ij}/k_j\)</span>, where <span class="math inline">\(k_j\)</span> is the degree of node <span class="math inline">\(j\)</span> and <span class="math inline">\(\mathbf{K}\)</span> is the diagonal matrix whose <span class="math inline">\(jj\)</span>th entry is <span class="math inline">\(k_j\)</span>.</p>
</div>
</div>
</div>
</div>
<div class="callout-caution callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><em>Exercise</em></strong>: Let <span class="math inline">\(p_{ij}\)</span> denote the entries of <span class="math inline">\(\mathbf{P}\)</span>. Check that <span class="math inline">\(\sum_{i \in N} p_{ij} = 1\)</span>, and interpret this fact.</p>
</div>
</div>
</div>
<p>What does the transition matrix do? Well, we can use the law of total probability to write: <span class="math display">\[
\begin{aligned}
\mathbb{P}(X_{t+1} = i) &amp;= \sum_{j \in N}\mathbb{P}(X_{t+1} = i|X_{t} = j)\mathbb{P}(X_t = j) \\
&amp;= \sum_{j \in N}p_{ij}\mathbb{P}(X_t = j)\;.
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(\mathbf{q}(t)\)</span> be the vector with entries <span class="math inline">\(q_i(t) = \mathbb{P}(X_{t} = i)\)</span>. We have just shown the most important relation in the study of random walks and their generalizations, Markov chains:</p>
<div class="callout-tip callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><span id="eq-transition"><span class="math display">\[
\mathbf{q}(t+1) = \mathbf{P}\mathbf{q}(t)
\qquad(6.1)\]</span></span></p>
</div>
</div>
</div>
<p><a href="#eq-transition">Equation&nbsp;<span>6.1</span></a> has an immediate consequence: <span class="math inline">\(\mathbf{q}(t) = \mathbf{P}^{t}\mathbf{q}(0)\)</span>. So, if we know the <em>initial distribution</em> <span class="math inline">\(\mathbf{q}(0)\)</span> describing the location at which the walker begins, we can get all other information we need from the matrix <span class="math inline">\(\mathbf{P}\)</span> and its powers.</p>
<section id="stationary-distribution-existence-and-uniqueness" class="level3">
<h3 class="anchored" data-anchor-id="stationary-distribution-existence-and-uniqueness">Stationary Distribution: Existence and Uniqueness</h3>
<p>Throughout this section, we assume that the graph <span class="math inline">\(G\)</span> is connected.</p>
<div class="callout-note callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>We say that an SRW has a <em>stationary distribution</em> <span class="math inline">\(\pi \in \mathbb{R}^n\)</span> if <span class="math inline">\(\lim_{t\rightarrow \infty} \mathbf{q}(t) = \mathbf{\pi}\)</span>, <em>regardless of the initial distribution</em> <span class="math inline">\(\mathbf{q}(0)\)</span>.</p>
</div>
</div>
</div>
<div class="callout-note callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-periodic" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6.3 </strong></span></p>
<p>A graph is <em>aperiodic</em> if the greatest common divisor of lengths of its cyclse is 1. A graph is <em>periodic</em> if it is not aperiodic.</p>
</div>
</div>
</div>
</div>
<p>A simple example of a periodic graph is a <span class="math inline">\(k\)</span>-cycle. A less simple example is a <em>bipartite graph</em>, in which each node can be separated into one of two classes <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> such that nodes in <span class="math inline">\(S_1\)</span> only connect to nodes in <span class="math inline">\(S_2\)</span> (and not to any other nodes in <span class="math inline">\(S_1\)</span>). You can check that bipartiteness implies that every cycle has length divisible by 2, so the graph is periodic.</p>
<div class="callout-tip callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-stationary" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.1 </strong></span>Suppose that <span class="math inline">\(G\)</span> is connected and aperiodic. Then,</p>
<ul>
<li><span class="math inline">\(G\)</span> has a stationary distribution <span class="math inline">\(\pi\)</span>.</li>
<li>This stationary distribution is unique.</li>
<li>The stationary distribution is the unique eigenvector of the transition matrix <span class="math inline">\(\mathbf{P}\)</span> with eigenvalue <span class="math inline">\(1\)</span>.</li>
</ul>
</div>
</div>
</div>
</div>
<p><a href="#thm-stationary">Theorem&nbsp;<span>6.1</span></a> is actually a theorem about discrete-time finite-state Markov chains in general, and its full proof is beyond the scope of this course. Here’s a sketch:</p>
<ol type="1">
<li>The condition that <span class="math inline">\(G\)</span> is connected implies that the matrix <span class="math inline">\(\mathbf{P}\)</span> is <a href="https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem#Classification_of_matrices">irreducible</a>.</li>
<li>This allows us to apply the <a href="https://en.wikipedia.org/wiki/Perron–Frobenius_theorem">Perron-Frobenius theorem</a> to conclude that <span class="math inline">\(\mathbf{P}\)</span> has a unique eigenvector with strictly positive entries, which we’ll call <span class="math inline">\(\pi\)</span>. Since <span class="math inline">\(\mathbf{P}\)</span> has rows that sum to 1, a direct calculation shows that the corresponding eigenvector of <span class="math inline">\(\pi\)</span> is unity, and we have <span class="math inline">\(\pi = \mathbf{P}\pi\)</span>.</li>
<li>One further shows that <span class="math inline">\(\lim_{t \rightarrow \infty}\mathbf{P}^t\)</span> exists and that its rows become equal to the eigenvector <span class="math inline">\(\pi\)</span> (this is related to power iteration).</li>
<li>Because each row of limiting matrix describe the long-run behavior of the random walk from a given starting node, one infers that <span class="math inline">\(\pi\)</span> is indeed a stationary state. Because all the rows agree in the limit, one infers that <span class="math inline">\(\pi\)</span> is the only such stationary state.</li>
</ol>
</section>
<section id="stationary-distribution-structure" class="level3">
<h3 class="anchored" data-anchor-id="stationary-distribution-structure">Stationary Distribution: Structure</h3>
<p>We know from <a href="#thm-stationary">Theorem&nbsp;<span>6.1</span></a> that there is a unique stationary distribution for the simple random walk, and that this distribution describes, in the long-term, the amount of time that the walker spends on a node. What actually <em>is</em> the stationary distribution? For many Markov chains, including more complicated random walks, it can be difficult to describe the stationary distribution exactly. In this case the answer is surprisingly simple, although it’s one of those things that’s much easier to check than it is to find in the first place.</p>
<div class="callout-note callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-degree" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.2 (Stationary Distribution of an SRW) </strong></span></p>
<p>The stationary distribution of an SRW is <span class="math inline">\(\pi = \frac{1}{2m}\mathbf{k}\)</span>, where <span class="math inline">\(\mathbf{k}\)</span> is the vector of node degrees.</p>
</div>
</div>
</div>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We can do a direct calculation:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{P}\pi = \mathbf{A}\mathbf{K}^{-1}\left(\frac{1}{2m}\mathbf{k}\right) = \frac{1}{2m}\mathbf{A}\mathbf{1}
= \frac{1}{2m}\mathbf{k}
= \pi\;.
\end{aligned}
\]</span></p>
<p>For the second equality we have used the quickly-checked identity <span class="math inline">\(\mathbf{K}^{-1}\mathbf{k} = \mathbf{1}\)</span>, while for the third we have used the formula <span class="math inline">\(\mathbf{k} = \mathbf{A}\mathbf{1}\)</span>.</p>
</div>
<p>So, for simple random walks, <span class="math inline">\(\mathbb{P}(X_t = i)\)</span> when <span class="math inline">\(t\)</span> is large is approximately <span class="math inline">\(k_i/2m\)</span>, proportional to the degree of node <span class="math inline">\(i\)</span>. The intuition here is that the amount of time I spend in state is directly proportional to the number of ways that I can enter that state.</p>
</section>
</section>
<section id="exploration-and-ranking-pagerank" class="level2 page-columns page-full" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="exploration-and-ranking-pagerank"><span class="header-section-number">6.2</span> Exploration and Ranking: PageRank</h2>
<div class="page-columns page-full"><p>PageRank is the algorithm that originally made Google a dominant player in the domain of web search. The idea of PageRank is again to explore the graph using a random exploration process. The underlying process is closely related to the simple random walk that we described earlier. However, there are two important differences.</p><div class="no-row-height column-margin column-container"><span class="aside"><span class="citation" data-cites="brin1998anatomy">Brin and Page (<a href="../appendices/references.html#ref-brin1998anatomy" role="doc-biblioref">1998</a>)</span></span></div></div>
<ol type="1">
<li>First, PageRank works on <em>directed</em> graphs. This matches the original application area; the web can be viewed as a <em>directed</em> network of links between pages. The reason directedness is so important is that, if <span class="math inline">\(i \rightarrow j\)</span> (<span class="math inline">\(i\)</span> links to <span class="math inline">\(j\)</span>), it doesn’t follow that <span class="math inline">\(j\rightarrow i\)</span>. Capturing these kinds of asymmetric relationships is very important for reasonable ranking procedures.</li>
<li>Unlike the SRW, PageRank is able to explore graphs that are non-ergodic.</li>
</ol>
<p>So, suppose we have a <em>directed</em> graph with adjacency matrix <span class="math inline">\(\mathbf{A}\)</span>. The important thing to remember is that now <span class="math inline">\(\mathbf{A}\)</span> is not required to be symmetric. We interpret the entries of the adjacency matrix so that <span class="math inline">\(a_{ij} = 1\)</span> if <span class="math inline">\(j \rightarrow i\)</span>. Since <span class="math inline">\(\mathbf{A}\)</span> need not be symmetric, <span class="math inline">\(a_{ij} \neq a_{ji}\)</span> in general.</p>
<p>The definition of a random walk on a directed graph is very similar to the definition on an undirected graph. It is again a sequence of random variables with the Markov property; only the transition probabilities differ.</p>
<div class="callout-note callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-directed-SRW" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6.4 (Simple Random Walk on a Directed Graph) </strong></span></p>
<p>The SRW on a directed graph has transition probabilities <span class="math display">\[
\mathbb{P}(X_{t+1} = i | X_t = j) = \frac{a_{ij}}{k_j^{\mathrm{out}}}\;,
\]</span> where <span class="math inline">\(k_j^{\mathrm{out}} = \sum_{i \in N}a_{ij}\)</span> is the number of outgoing links from node <span class="math inline">\(j\)</span>. The transition matrix of this walk is <span class="math display">\[
\mathbf{P} = \mathbf{A}(\mathbf{K}^{\mathrm{out}})^{-1}\;.
\]</span></p>
</div>
</div>
</div>
</div>
<div class="callout-caution callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Because <span class="math inline">\(\mathbf{A}\)</span> is not symmetric, we can also define <span class="math inline">\(k_j^{\mathrm{in}} = \sum_{j \in N}a_{ij}\)</span>, the number of incoming links to node <span class="math inline">\(j\)</span>. Importantly, <span class="math inline">\(k_j^{\mathrm{in}} \neq k_j^{\mathrm{out}}\)</span> in general.</p>
</div>
</div>
</div>
<p>Many of the same considerations from the undirected setting carry over to the directed setting.</p>
<div class="callout-tip callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-stationary-directed" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.3 (Stationary Distributions of Directed Random Walks) </strong></span>Suppose that:</p>
<ol type="1">
<li>There exists some integer power <span class="math inline">\(t &gt; 0\)</span> such that every entry of <span class="math inline">\(\mathbf{A}^t\)</span> is positive.</li>
<li>The greatest common divisor of the <em>directed</em> cycles in <span class="math inline">\(G\)</span> is 1.</li>
</ol>
<p>Then, the SRW on <span class="math inline">\(G\)</span> has a stationary distribution <span class="math inline">\(\pi\)</span>, which is a solution of the eigenproblem <span class="math display">\[
\pi = \mathbf{P}\pi\;.
\]</span></p>
</div>
</div>
</div>
</div>
<p>Condition (1) in <a href="#thm-stationary-directed">Theorem&nbsp;<span>6.3</span></a> is essentially a connectedness condition: it says that there has to be a directed path from every node to every other node in the network. So, as you might reasonably expect, the directed random walk doesn’t really overcome the need for the graph to be connected. This can be a problem for network exploration, as it’s more common for directed networks to not be connected in this way.[A bit more subtly, directed graphs that are <em>almost</em> disconnected are subject to <em>slow mixing</em> of the random walk, which implies very inefficient exploration of the network.] PageRank overcomes this limitation by allowing the walker to randomly hop to new nodes, independent of the network structure.</p>
<div class="callout-note callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-pagerank-walk" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6.5 (PageRank Random Walk) </strong></span>The <strong>PageRank random walk</strong> has two parameters:</p>
<ul>
<li>The <em>teleportation vector</em> <span class="math inline">\(\mathbf{v} \in \mathbb{R}^n_+\)</span>, which we assume to satisfy <span class="math inline">\(\sum_{i\in N}v_i = 1\)</span>.</li>
<li>The <em>teleportation rate</em> <span class="math inline">\(\alpha\in [0,1]\)</span>.</li>
</ul>
<p>This walk has transition probabilities <span id="eq-pagerank-transition"><span class="math display">\[
\mathbb{P}(X_{t+1} = i|X_{t}=j) = (1-\alpha)\frac{a_{ij}}{k_j^{\mathrm{out}}} + \alpha v_i\;.
\qquad(6.2)\]</span></span></p>
<p>Its transition matrix is</p>
<p><span class="math display">\[
\mathbf{P} = (1-\alpha) \mathbf{A}(\mathbf{K}^{\mathrm{out}})^{-1} + \alpha \mathbf{V}\;,
\]</span></p>
<p><span class="math display">\[
\mathbf{V} = \left[\begin{matrix}
    - &amp; \mathbf{v} &amp; - \\
    - &amp; \mathbf{v} &amp; - \\
    \vdots &amp; \vdots &amp; \vdots \\
    - &amp; \mathbf{v} &amp; -
\end{matrix}\right]\;.
\]</span></p>
</div>
</div>
</div>
</div>
<p>Here’s the intuitive way to think about this walk. At each time step, the walker flips a weighted coin with probability of heads equal to <span class="math inline">\(\alpha\)</span>.</p>
<ul>
<li>If heads, the walker chooses to sample from the probability distribution encoded by <span class="math inline">\(\mathbf{v}\)</span>. That is, the walker chooses from among all the nodes in <span class="math inline">\(N\)</span>, and picks node <span class="math inline">\(i\)</span> with probability <span class="math inline">\(v_i\)</span>.</li>
<li>If tails, the walker instead follows a link, just like in the directed random walk.</li>
</ul>
<p>This is why there are two terms in the transition probability in <a href="#eq-pagerank-transition">Equation&nbsp;<span>6.2</span></a>. The first term corresponds to the “tails” scenario in which the walker does a step corresponding to the directed random walk, while the second term corresponds to teleportation.</p>
<p>The standard choice of the teleportation vector is <span class="math inline">\(\mathbf{v} = \frac{1}{n}\mathbf{1}\)</span>, so each node has an equal probability of being chosen for teleportation. However, it’s also possible to take other approaches, as we’ll see in a moment.</p>
<div class="callout-note callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-pagerank" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.4 (Stationary Distribution of PageRank) </strong></span></p>
<p>Suppose that there exists an integer power <span class="math inline">\(t\)</span> such that <span class="math inline">\(\mathbf{P}^t\)</span> has all entries strictly positive. Then, the PageRank random walk has a unique stationary distribution, and this distribution may again be found by solving <span class="math inline">\(\pi = \mathbf{P}\pi\)</span>.</p>
</div>
</div>
</div>
</div>
<div class="callout-caution callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Exercise</strong>: Show that, when <span class="math inline">\(\mathbf{v} = \frac{1}{n}\mathbf{1}\)</span>, <a href="#thm-pagerank">Theorem&nbsp;<span>6.4</span></a> implies that the PageRank walk always has a stationary distribution, regardless of the graph.</p>
</div>
</div>
</div>
<div class="callout-caution callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Challenge</strong>: Give a necessary and sufficient condition in terms of <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> for PageRank to have a stationary distribution.</p>
</div>
</div>
</div>
<section id="implementation" class="level3">
<h3 class="anchored" data-anchor-id="implementation">Implementation</h3>
<p>Let’s code up a quick example to visualize PageRank. We’ll use the Hamilton Mentions graph:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode" id="cb1"><pre class="sourceCode python cell-code code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"https://philchodrow.github.io/PIC16A/homework/HW3-hamilton-data.csv"</span>, </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> [<span class="st">"mentioner"</span>, <span class="st">"mentioned"</span>])</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">"mentioner"</span>] <span class="op">!=</span> df[<span class="st">"mentioned"</span>]]</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.from_pandas_edgelist(df, </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>                            source <span class="op">=</span> <span class="st">"mentioner"</span>, </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                            target <span class="op">=</span> <span class="st">"mentioned"</span>, </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>                            edge_attr<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>                            create_using<span class="op">=</span>nx.DiGraph())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>There are a few nodes in this network with no outgoing edges. while there are modifications we can make to handle this kind of case, we can also just remove them from the graph.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode" id="cb2"><pre class="sourceCode python cell-code code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    G <span class="op">=</span> G.subgraph([name <span class="cf">for</span> name, val <span class="kw">in</span> G.out_degree() <span class="cf">if</span> val <span class="op">&gt;</span> <span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can write our PageRank function. We’ll compute the transition matrix <span class="math inline">\(\mathbf{P}\)</span> and find its leading eigenvector.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode" id="cb3"><pre class="sourceCode python cell-code code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pagerank(G, v, alpha <span class="op">=</span> <span class="fl">0.15</span>):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> np.isclose(v.<span class="bu">sum</span>(), <span class="fl">1.0</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># construct the PR transition matrix</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    A  <span class="op">=</span> nx.to_numpy_array(G).T</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    K  <span class="op">=</span> np.diag(A.<span class="bu">sum</span>(axis <span class="op">=</span> <span class="dv">0</span>))     <span class="co"># K^out</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    P_ <span class="op">=</span> A<span class="op">@</span>np.linalg.inv(K)           <span class="co"># random walk matrix</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    V  <span class="op">=</span> np.outer(v, np.ones(<span class="bu">len</span>(v))) <span class="co"># teleportation matrix</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    P <span class="op">=</span> (<span class="dv">1</span><span class="op">-</span>alpha)<span class="op">*</span>P_ <span class="op">+</span> alpha<span class="op">*</span>V        <span class="co"># overall transition matrix</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># grab the eigenvector with eigenvalue 1, normalize it and return. </span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    eigs <span class="op">=</span> np.linalg.eig(P)        </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    pi <span class="op">=</span> eigs[<span class="dv">1</span>][:,np.isclose(eigs[<span class="dv">0</span>], <span class="fl">1.0</span>)]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    pi <span class="op">=</span> np.<span class="bu">abs</span>(pi) <span class="op">/</span> np.<span class="bu">abs</span>(pi).<span class="bu">sum</span>()</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pi</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode" id="cb4"><pre class="sourceCode python cell-code code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> draw_pagerank(G, v,  layout, alpha <span class="op">=</span> <span class="fl">0.15</span>):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    pi <span class="op">=</span> pagerank(G, v, alpha <span class="op">=</span> alpha)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    nx.draw(G, layout, </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>            node_size <span class="op">=</span> <span class="dv">5000</span><span class="op">*</span>pi, </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>            with_labels <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>            edge_color <span class="op">=</span> <span class="st">"lightgray"</span>, </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>            node_color <span class="op">=</span> <span class="st">"lavender"</span>,</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>            edgecolors  <span class="op">=</span> <span class="st">"darkgray"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can visualize the PageRank stationary distribution for different choices of the teleportation vector <span class="math inline">\(\mathbf{v}\)</span> and the teleportation rate <span class="math inline">\(\alpha\)</span>:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode" id="cb5"><pre class="sourceCode python cell-code code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>layout <span class="op">=</span> nx.fruchterman_reingold_layout(G)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(G.nodes())</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>n<span class="op">*</span>np.ones(n)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>draw_pagerank(G, v, layout, alpha <span class="op">=</span> <span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ranking_centrality_files/figure-html/cell-6-output-1.png" class="" width="691" height="499"></p>
</div>
</div>
</section>
</section>
<section id="seeded-pagerank" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="seeded-pagerank"><span class="header-section-number">6.3</span> Seeded PageRank</h2>
<p>A useful feature of the way we’ve defined PageRank is that we can choose different teleportation vectors <span class="math inline">\(\mathbf{v}\)</span> in order to explore different parts of the graph. For example, suppose that we are especially interested in the part of the network surrouding certain characters. We can just change the teleportation vector <span class="math inline">\(\mathbf{v}\)</span> to highlight those specific characters. This approach is often called “personalized” or “seeded” PageRank.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode" id="cb6"><pre class="sourceCode python cell-code code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> np.array([<span class="dv">1</span> <span class="cf">if</span> i <span class="op">==</span> <span class="st">"kingGeorge"</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">list</span>(G.nodes())])</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>draw_pagerank(G, v, layout, alpha <span class="op">=</span> <span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ranking_centrality_files/figure-html/cell-7-output-1.png" class="" width="691" height="499"></p>
</div>
</div>
<p>This time, we’ve highlighted the node corresponding to the character King George. Whereas when using the “basic” version of PageRank Hamilton, Burr, Washington, and Jefferson are all very important characters, in the personalized versio, Washington emerges as clearly the most important.</p>
<p>This kind of idea is often applied in marketing and search. Suppose we know that a user is interested in site <span class="math inline">\(A\)</span>. Then, if that user searches for something online, we can use that information by computing a PageRank ranking and returning the top nodes, <em>using a biased teleportation vector</em>. This would allow us to balance the objectives of returning webpages that are relevant <em>overall</em> and webpages that are especially relevant <em>for that user</em>.</p>



</section>
</main> <!-- /main -->
<script type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    setTimeout(function() {
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/clustering_community.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Clustering and Community Detection</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/agent_based_modeling.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Agent-Based Modeling on Networks</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->


</body></html>